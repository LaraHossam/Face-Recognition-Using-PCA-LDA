{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ea043e",
   "metadata": {},
   "source": [
    "## Assignment #1 Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652ff202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d37b2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2028638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def classify_knn(train_x, train_y, test_x, test_y, k=1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_x, train_y)\n",
    "    accuracy = knn.score(test_x, test_y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae78a9",
   "metadata": {},
   "source": [
    "### 1. Download the Dataset and Understand the Format (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32788d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the loaded images\n",
    "faces = {}\n",
    "\n",
    "# Open the Zip archive and iterate over the files\n",
    "with zipfile.ZipFile(\"archive.zip\") as folder:\n",
    "    for filename in folder.namelist():\n",
    "\n",
    "        # Check if the file is a PGM image\n",
    "        if filename.endswith('.pgm'):\n",
    "\n",
    "            # Open the file and read its contents into a buffer\n",
    "            with folder.open(filename) as image:\n",
    "                arr = np.frombuffer(image.read(), np.uint8)\n",
    "\n",
    "            # Decode the buffer as a grayscale image using OpenCV\n",
    "            # and store it in the dictionary\n",
    "            faces[filename] = cv.imdecode(arr, cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c544a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dimensions of a random image from the dictionary\n",
    "faces['s12/8.pgm'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of the filenames stored as the key values in the faces dictionary\n",
    "file_names = list(faces.keys())\n",
    "print(file_names[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a 6x6 grid of subplots that share the same x and y axes\n",
    "figure, axis = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(8, 10))\n",
    "\n",
    "# Initialize an empty list to store the images to plot, 10 steps each time to cover as many faces as possible\n",
    "images = []\n",
    "for i in range(36):\n",
    "    images.append(list(faces.values())[i * 10])\n",
    "for i in range(36):\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    axis[row][col].imshow(images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8546aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(3, 3, sharex=True, sharey=True, figsize=(8, 10))\n",
    "images = []\n",
    "for i in range(9):\n",
    "    images.append(list(faces.values())[i])\n",
    "\n",
    "# Display 9 images for the same subject to get an idea of how data looks like\n",
    "for i in range(9):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    axis[row][col].imshow(images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372094f4",
   "metadata": {},
   "source": [
    "### 2. Generate the Data Matrix and the Label vector (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249d08c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Get the dimensions of the grayscale image\n",
    "n_x = faces[file_names[0]].shape[0]\n",
    "n_y = faces[file_names[0]].shape[1]\n",
    "\n",
    "#Initialize the data matrix array to stack the samples\n",
    "data = np.empty((n_x*n_y, 0))\n",
    "\n",
    "#Initialize list of classes\n",
    "label = []\n",
    "for i in range(len(faces.keys())):\n",
    "    faces[file_names[i]]=faces[file_names[i]].reshape(n_x*n_y,1)\n",
    "    data = np.hstack((data,faces[file_names[i]]))\n",
    "    label.append(file_names[i].split(\"/\")[0][1:])\n",
    "label = np.array(label).reshape((400,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772cd93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64181659",
   "metadata": {},
   "source": [
    "### 3. Split the Dataset into Training and Testing Test sets (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60980520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Dataset, even rows for testing and odd for training\n",
    "test_x = data.T[::2]\n",
    "test_y = label[::2]\n",
    "train_x = data.T[1::2]\n",
    "train_y = label[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfe2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0cdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a77f03",
   "metadata": {},
   "source": [
    "### 4. Classification using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09d03a",
   "metadata": {},
   "source": [
    "<img src=\"pca.png\" width=\"80%\" height=\"80%\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f698dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.8,0.85,0.9,0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(train_x,axis=0,keepdims=True)\n",
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa98775",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = train_x - mu\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef57ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.matmul(Z.T,Z)\n",
    "cov /= Z.shape[0]\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d509d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eigh(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8606b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort eigen vectors according to the descending order of corresponding eigen values\n",
    "idx = eigen_values.argsort()[::-1]\n",
    "eigen_values = eigen_values[idx]\n",
    "eigen_vectors = eigen_vectors[:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_eigen = float(np.sum(eigen_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the number of eigen vectors in the eigen face according to the accuracy we defined, we have an array alphas of all\n",
    "#accuracies desired, we return a corresponding array with the number of eigen vectors starting from 0\n",
    "var = 0\n",
    "num_eigen = 0\n",
    "final_rank = []\n",
    "temp_sum = 0\n",
    "for i in alpha:\n",
    "    while var < i:\n",
    "        temp_sum += eigen_values[num_eigen]\n",
    "        var = temp_sum/sum_eigen\n",
    "        num_eigen += 1\n",
    "    final_rank.append(num_eigen)\n",
    "    var=0\n",
    "    num_eigen=0\n",
    "    temp_sum=0\n",
    "print(final_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c896a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the projection matrix using the first alpha (Accuracy threshold)\n",
    "projection = eigen_vectors[:,:final_rank[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9872f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d56035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigenfaces\n",
    "fig, ax = plt.subplots(nrows=6, ncols=6, figsize=(10, 10))\n",
    "for i, row in enumerate(ax):\n",
    "    for j, col in enumerate(row):\n",
    "        index = i * 6 + j\n",
    "        eigenface = eigen_vectors[:, index]\n",
    "        col.imshow(eigenface.reshape(112, -1), cmap='gray')\n",
    "        col.set_xticks([])\n",
    "        col.set_yticks([])\n",
    "        col.set_title(f\"Eigenface {index+1}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the accuracy with respect to each alpha using KNN with 1 neighbor\n",
    "print(f'K = 1')\n",
    "accuracy = {}\n",
    "\n",
    "#Get the centered train and test to project them to the new dimensions represented as the projection matrix\n",
    "train_x1 = train_x - mu\n",
    "test_x1 = test_x - mu\n",
    "for i in range(len(final_rank)):\n",
    "    projection = eigen_vectors[:,:final_rank[i]]\n",
    "    train_x_new= np.dot(train_x1,projection)\n",
    "    test_x_new= np.dot(test_x1,projection)\n",
    "    org_accuracy = classify_knn(train_x_new, train_y, test_x_new, test_y, k=1)\n",
    "    accuracy[alpha[i]] = org_accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the alpha values against the accuracy\n",
    "x = accuracy.keys()\n",
    "y = accuracy.values()\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11a6cb",
   "metadata": {},
   "source": [
    "### 5. Classification using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d342083",
   "metadata": {},
   "source": [
    "<img src=\"lda.png\" width=\"80%\" height=\"80%\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6e029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed94a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109844be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09ec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_int = train_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_new = train_y_int.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c1e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean vector for every class [1-40]\n",
    "means = np.zeros((40,10304))\n",
    "for i in range(1,41):\n",
    "    means[i-1] = np.mean(train_x[train_y_new == i],axis=0,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab74f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate between class scatter matrix\n",
    "m = 40 # number of classes\n",
    "k = 5 # number of samples per class\n",
    "N = 10304 # number of features\n",
    "\n",
    "#Initialize the between class scatter matrix to 0 having the dimensions of features x features\n",
    "Sb = np.zeros((train_x.shape[1],train_x.shape[1]))\n",
    "mu = mu.reshape(N, 1)\n",
    "for mean in means:\n",
    "    mean = mean.reshape(N, 1)\n",
    "    Sb += k*np.dot((mean-mu),(mean-mu).T)\n",
    "Sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d5e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the mean from each class\n",
    "# Center data class matrices\n",
    "Z = []\n",
    "for i, mean in enumerate(means):\n",
    "    idx = i+1\n",
    "    mean = mean.reshape(1,N)\n",
    "    \n",
    "    #Query the train_x matrix using the train_y value to get the class then subtracting the mean of the corresponding class\n",
    "    Z.append(train_x[train_y_new == idx] - mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd534f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_all = np.array(Z).reshape(-1,np.shape(Z)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59069aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the total scatter matrix to 0\n",
    "S = np.zeros((N,N))\n",
    "for i in range(40):\n",
    "    Z_arr = np.array(Z[i])\n",
    "    S += (Z_arr.T).dot(Z_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5988e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_inverse=np.linalg.inv(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values_2,eigen_vectors_2 = np.linalg.eigh(np.dot(S_inverse,Sb)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort eigen vectors according to the descending order of corresponding eigen values\n",
    "idx = eigen_values_2.argsort()[::-1]\n",
    "eigen_values_2 = eigen_values_2[idx]\n",
    "eigen_vectors_2 = eigen_vectors_2[:,idx]\n",
    "p = eigen_vectors_2[:,:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11596aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec655a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projecting the train_x and test_x to the new dimensions(39 eigen vector) and fininding the accuracy of the LDA using KNN\n",
    "print(f'K = 1')\n",
    "d_train_x_new= np.dot(train_x,p)\n",
    "d_test_x_new= np.dot(test_x,p)\n",
    "org_accuracy = classify_knn(d_train_x_new, train_y, d_test_x_new, test_y,1)\n",
    "print(f'Accuracy: {org_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e861a9",
   "metadata": {},
   "source": [
    "### 6. Classifier Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97c1db",
   "metadata": {},
   "source": [
    "Tie breaking is done using the default rule of the sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2661aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy for each number of neighbors in the KNN array for the different values of alphas\n",
    "#Using original data not the centered data (both lead to the same results)\n",
    "KNN = [1,3,5,7]\n",
    "best_acc = []\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    accuracy = {}\n",
    "    for i in range(len(final_rank)):\n",
    "        projection = eigen_vectors[:,:final_rank[i]]\n",
    "        train_x_new= np.dot(train_x,projection)\n",
    "        test_x_new= np.dot(test_x,projection)\n",
    "        org_accuracy = classify_knn(train_x_new, train_y, test_x_new, test_y, k=KNN[j])\n",
    "        accuracy[alpha[i]] = org_accuracy\n",
    "        if alpha[i] == 0.95:\n",
    "            best_acc.append(org_accuracy)\n",
    "    print(accuracy)\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting PCA accuracy of the highest alpha against number of neighbors\n",
    "x = KNN\n",
    "y = best_acc\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"K-neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy for each number of neighbors in the KNN array\n",
    "KNN = [1,3,5,7]\n",
    "LDA_accuracies=[]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    train_x_new= np.dot(train_x,p)\n",
    "    test_x_new= np.dot(test_x,p)\n",
    "    org_accuracy = classify_knn(train_x_new, train_y, test_x_new, test_y, k=KNN[j])\n",
    "    print(f\"Accuracy={org_accuracy}\")\n",
    "    LDA_accuracies.append(org_accuracy)\n",
    "print(LDA_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting LDA accuracy against number of neighbors\n",
    "x = KNN\n",
    "y = LDA_accuracies\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"K-neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730f448",
   "metadata": {},
   "source": [
    "### 7. Compare vs Non-Face Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bea37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the loaded images\n",
    "non_faces = {}\n",
    "\n",
    "# Open the Zip archive and iterate over the files\n",
    "with zipfile.ZipFile(\"non_image.zip\") as folder:\n",
    "    for filename in folder.namelist():\n",
    "\n",
    "        # Check if the file is a PGM image\n",
    "        if filename.endswith('.jpg'):\n",
    "\n",
    "            # Open the file and read its contents into a buffer\n",
    "            with folder.open(filename) as image:\n",
    "                arr = np.frombuffer(image.read(), np.uint8)\n",
    "\n",
    "            # Decode the buffer as a grayscale image using OpenCV\n",
    "            # and store it in the dictionary\n",
    "            non_faces[filename] = cv.imdecode(arr, cv.IMREAD_GRAYSCALE)\n",
    "            non_faces[filename] = cv.resize(non_faces[filename] , (92, 112))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfddee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_faces['non_image/airplane/airplane_0003.jpg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971a8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a 6x6 grid of subplots that share the same x and y axes\n",
    "figure, axis = plt.subplots(6, 6, sharex=True, sharey=True, figsize=(8, 10))\n",
    "\n",
    "# Initialize an empty list to store the images to plot, 10 steps each time to cover as many faces as possible\n",
    "images = []\n",
    "for i in range(36):\n",
    "    images.append(list(non_faces.values())[i * 10])\n",
    "for i in range(36):\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    axis[row][col].imshow(images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_faces.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list(non_faces.keys())\n",
    "\n",
    "#Get the dimensions of the grayscale image\n",
    "n_x = non_faces[file_names[0]].shape[0]\n",
    "n_y = non_faces[file_names[0]].shape[1]\n",
    "\n",
    "#Initialize the data matrix array to stack the samples\n",
    "data_non_faces = np.empty((n_x*n_y, 0))\n",
    "\n",
    "#Initialize list of classes\n",
    "label = []\n",
    "for i in range(len(non_faces.keys())):\n",
    "    non_faces[file_names[i]]=non_faces[file_names[i]].reshape(n_x*n_y,1)\n",
    "    data_non_faces = np.hstack((data_non_faces,non_faces[file_names[i]]))\n",
    "    label.append(file_names[i].split(\"/\")[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63107cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_non_faces = data_non_faces.T[::2]\n",
    "train_x_non_faces = data_non_faces.T[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9717c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_faces = np.ones((200,1))\n",
    "train_y_faces = np.ones((200,1))\n",
    "test_y_non_faces = np.zeros((200,1))\n",
    "train_y_non_faces = np.zeros((200,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_non_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897744b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.vstack((train_x,train_x_non_faces))\n",
    "test_x=np.vstack((test_x,test_x_non_faces))\n",
    "test_y=np.vstack((test_y_faces,test_y_non_faces))\n",
    "train_y=np.vstack((train_y_faces,train_y_non_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for PCA\n",
    "class PCA():\n",
    "    def __init__(self):\n",
    "        print(\"Starting PCA\")\n",
    "    \n",
    "    def compute_mean(self):\n",
    "        self.mean = np.mean(self.data,axis=0,keepdims=True)\n",
    "\n",
    "    def center(self):\n",
    "        self.Z = self.data - self.mean\n",
    "        \n",
    "    def cov(self):\n",
    "        self.covar = (self.Z.T).dot(self.Z)\n",
    "        self.covar /= self.Z.shape[0]\n",
    "#         print(self.covar.shape)\n",
    "        \n",
    "    def eigen_decomp(self):\n",
    "        self.eigen_val,self.eigen_vector = np.linalg.eigh(self.covar)\n",
    "        idx = self.eigen_val.argsort()[::-1]\n",
    "        self.eigen_val = self.eigen_val[idx]\n",
    "        self.eigen_vector = self.eigen_vector[:,idx]\n",
    "        \n",
    "    def project(self):\n",
    "        self.test_x = test_x\n",
    "    \n",
    "    def reduce(self,alpha):\n",
    "        sum_eigen=float(np.sum(self.eigen_val))\n",
    "        self.alpha = alpha\n",
    "        var = 0\n",
    "        num_eigen = 0\n",
    "        temp_sum = 0\n",
    "        while var < self.alpha:\n",
    "            temp_sum += self.eigen_val[num_eigen]\n",
    "            var = temp_sum/sum_eigen\n",
    "            num_eigen += 1\n",
    "        self.dimensions = num_eigen\n",
    "#         print(f\"Number of eigenvectors: {self.dimensions}\")\n",
    "\n",
    "    def project(self,test):\n",
    "        self.test_x = test\n",
    "        self.projection=self.eigen_vector[:,:self.dimensions]\n",
    "        self.new_train_x=self.data.dot(self.projection)\n",
    "        self.new_test_x=self.test_x.dot(self.projection)\n",
    "    \n",
    "    def classify(self,k,test_y,train_y):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(self.new_train_x, train_y)\n",
    "        accuracy = knn.score(self.new_test_x, test_y)\n",
    "        print(f\"{self.alpha}: {accuracy}\")\n",
    "        \n",
    "    def start(self,data):\n",
    "        self.data = data\n",
    "        self.compute_mean()\n",
    "        self.center()\n",
    "        self.cov()\n",
    "        self.eigen_decomp()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567848ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.start(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN=[1,3,5,7]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    for i in range(len(alpha)):\n",
    "        pca.reduce(alpha[i])\n",
    "        pca.project(test_x)\n",
    "        pca.classify(KNN[j],test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c104b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    def __init__(self):\n",
    "        print(\"Starting LDA\")\n",
    "        \n",
    "    def compute_mean(self):\n",
    "        self.mean_faces = np.mean(self.faces_data,axis=0,keepdims=True)\n",
    "        self.mean_nonfaces = np.mean(self.nonfaces_data,axis=0,keepdims=True)\n",
    "\n",
    "    def split_data(self):\n",
    "        self.faces_data = self.data[:200,:]\n",
    "        self.nonfaces_data = self.data[200:,:]\n",
    "        \n",
    "    def center(self):\n",
    "        self.Z_faces = self.faces_data - self.mean_faces\n",
    "        self.Z_nonfaces = self.nonfaces_data - self.mean_nonfaces\n",
    "        \n",
    "    def compute_B(self):\n",
    "        \n",
    "        # B -- Between class scatter matrix\n",
    "        d = np.reshape(self.mean_faces,(10304,1)) - np.reshape(self.mean_nonfaces,(10304,1))\n",
    "        self.B = d.dot(d.T)\n",
    "\n",
    "    \n",
    "    def compute_S(self):\n",
    "        self.S_1 = self.Z_faces.T.dot(self.Z_faces)\n",
    "        self.S_2 = self.Z_nonfaces.T.dot(self.Z_nonfaces)\n",
    "        self.S = self.S_1 + self.S_2\n",
    "        \n",
    "    def compute_eigen(self):\n",
    "        self.M = np.linalg.inv(self.S).dot(self.B)\n",
    "        self.eigen_val,self.eigen_vector = np.linalg.eigh(self.M)\n",
    "        idx = self.eigen_val.argsort()[::-1]\n",
    "        self.eigen_val = self.eigen_val[idx]\n",
    "        self.eigen_vector = self.eigen_vector[:,idx]\n",
    "            \n",
    "    def project(self,test,n):\n",
    "        self.n = n\n",
    "        self.test_x = test\n",
    "        self.projection=self.eigen_vector[:,:n]\n",
    "        self.new_train_x=self.data.dot(self.projection)\n",
    "        self.new_test_x=self.test_x.dot(self.projection)\n",
    "    \n",
    "    def classify(self,k,test_y,train_y):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(self.new_train_x, train_y)\n",
    "        accuracy = knn.score(self.new_test_x, test_y)\n",
    "        print(f\"{self.n} eigenvectors : {accuracy}\")\n",
    "        \n",
    "\n",
    "    def start(self,data):\n",
    "        self.data = data\n",
    "        self.split_data()\n",
    "        self.compute_mean()\n",
    "        self.center()\n",
    "        self.compute_B()\n",
    "        self.compute_S()\n",
    "        self.compute_eigen()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7c5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "lda.start(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN=[1,3,5,7]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    lda.project(test_x,1)\n",
    "    lda.classify(KNN[j],test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4aa92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN=[1,3,5,7]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    lda.project(test_x,40)\n",
    "    lda.classify(KNN[j],test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744fd13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Criticize the accuracy measure for large number of non-faces\n",
    "# images in the training data\n",
    "\n",
    "# PCA\n",
    "\n",
    "# Assuming alpha  = 0.9 and k = 1\n",
    "# Range of samples vary from 50 to 400, split evenly between\n",
    "# training and testing while keeping the face image dataset as it is\n",
    "n_i = [50,100,150,200]\n",
    "for n in n_i:\n",
    "    print(f\"Running PCA with {n} samples in non-faces VS 200 samples in faces\")\n",
    "    pca = PCA()\n",
    "    test_x = data.T[::2]\n",
    "    test_y = label[::2]\n",
    "    train_x = data.T[1::2]\n",
    "    train_y = label[1::2]\n",
    "    train_x=np.vstack((train_x,train_x_non_faces[:n,:]))\n",
    "    test_x=np.vstack((test_x,test_x_non_faces[:n,:]))\n",
    "    test_y=np.vstack((test_y_faces,test_y_non_faces[:n,:]))\n",
    "    train_y=np.vstack((train_y_faces,train_y_non_faces[:n,:]))\n",
    "    pca.start(train_x)\n",
    "    pca.reduce(0.9)\n",
    "    pca.project(test_x)\n",
    "    pca.classify(1,test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eaeb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting PCA accuracy against number of pictures in non face dataset\n",
    "x = [50,100,150,200]\n",
    "y = [0.904,0.8266,0.87428571,0.8925]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Number of non faces\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "\n",
    "# Assuming alpha  = 0.9 and k = 1\n",
    "# Range of samples vary from 50 to 400, split evenly between\n",
    "# training and testing while keeping the face image dataset as it is\n",
    "n_i = [50,100,150,200]\n",
    "for n in n_i:\n",
    "    print(f\"Running PCA with {n} samples in non-faces VS 200 samples in faces\")\n",
    "    lda = LDA()\n",
    "    test_x = data.T[::2]\n",
    "    test_y = label[::2]\n",
    "    train_x = data.T[1::2]\n",
    "    train_y = label[1::2]\n",
    "    train_x=np.vstack((train_x,train_x_non_faces[:n,:]))\n",
    "    test_x=np.vstack((test_x,test_x_non_faces[:n,:]))\n",
    "    test_y=np.vstack((test_y_faces,test_y_non_faces[:n,:]))\n",
    "    train_y=np.vstack((train_y_faces,train_y_non_faces[:n,:]))\n",
    "    lda.start(train_x)\n",
    "    lda.project(test_x,1)\n",
    "    lda.classify(1,test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ef22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting LDA accuracy against number of pictures in non face dataset\n",
    "x = [50,100,150,200]\n",
    "y = [0.96,0.933,0.917,0.935]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Number of non faces\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb777ae",
   "metadata": {},
   "source": [
    "### 8. Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e348fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dimensions of the grayscale image\n",
    "n_x = faces[file_names[0]].shape[0]\n",
    "n_y = faces[file_names[0]].shape[1]\n",
    "\n",
    "#Initialize the data matrix array to stack the samples\n",
    "data = np.empty((n_x*n_y, 0))\n",
    "\n",
    "label = []\n",
    "for i in range(len(faces.keys())):\n",
    "    faces[file_names[i]]=faces[file_names[i]].reshape(n_x*n_y,1)\n",
    "    data = np.hstack((data,faces[file_names[i]]))\n",
    "    label.append(file_names[i].split(\"/\")[0][1:])\n",
    "label = np.array(label).reshape((400,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3489829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using different train/test split 7-3 instead of 5-5\n",
    "data_new = data.T\n",
    "test_x = np.empty((0,10304))\n",
    "test_y =  np.empty((0,3*40))\n",
    "train_x = np.empty((0,10304))\n",
    "train_y =np.empty((0,7*40))\n",
    "train_samples = 7\n",
    "test_samples = 3\n",
    "# iterate through the dataset in steps of 10 rows\n",
    "for i in range(0, 400, 10):\n",
    "    # extract the training samples and append to the training array\n",
    "    train_x = np.append(train_x, data_new[i:i+train_samples,:],axis=0)\n",
    "    train_y = np.append(train_y, label[i:i+train_samples])\n",
    "    # extract the testing samples and append to the testing array\n",
    "    test_x = np.append(test_x, data_new[i+train_samples:i+train_samples+test_samples,:],axis=0)\n",
    "    test_y = np.append(test_y,label[i+train_samples:i+train_samples+test_samples])\n",
    "train_y = train_y.reshape(280,1)\n",
    "test_y = test_y.reshape(120,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4775a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y and train_y ----- BAYZEEN W LAZERM YETSALA70!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.start(train_x)\n",
    "KNN=[1,3,5,7]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    pca.reduce(0.95)\n",
    "    pca.project(test_x)\n",
    "    pca.classify(KNN[j],test_y,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ef72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()\n",
    "lda.start(train_x)\n",
    "KNN=[1,3,5,7]\n",
    "for j in range(4):\n",
    "    print(f'K = {KNN[j]}')\n",
    "    lda.project(test_x,50)\n",
    "    lda.classify(KNN[j],test_y,train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8af1b",
   "metadata": {},
   "source": [
    "### Variation of PCA and LDA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea1999",
   "metadata": {},
   "source": [
    "### IPCA, Incremental PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac023bd7",
   "metadata": {},
   "source": [
    "### KPCA, Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459b109",
   "metadata": {},
   "source": [
    "### RLDA, Regularized LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
